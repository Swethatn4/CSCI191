{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is a subfield of artificial intelligence (AI). The goal of machine learning generally is to understand the structure of data and fit that data into models that can be understood and utilized by people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Titanic Survival "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict if a passenger survived the sinking of the Titanic or not. For each PassengerId in the test set, we will predict a 0 or 1 value for the Survived variable. We will apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Followed these steps for all the kaggle competition submission\n",
    "1. Load the data\n",
    "2. check for null and missing values\n",
    "3. Feature analysis\n",
    "      3.1 Numerical values\n",
    "      3.2 Categorical values\n",
    "4. Filling missing Values\n",
    "5. Modeling\n",
    "6. Prediction\n",
    "7. Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=3)\n",
    "classifier.fit(train_X,train_Y)\n",
    "\n",
    "y_pred = classifier.predict(train_X)\n",
    "print (\"Accuracy on Training: \",classifier.score(train_X,train_Y))\n",
    "\n",
    "classifier.fit(test_X,test_Y)\n",
    "y_pred = classifier.predict(test_X)\n",
    "print (\"Accuracy on Testing: \",classifier.score(test_X,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a classification algorithm used to assign observations to a discrete set of classes. Unlike linear regression which outputs continuous number values, logistic regression transforms its output using the logistic sigmoid function to return a probability value which can then be mapped to two or more discrete classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) is a classification and regression prediction tool that uses machine learning theory to maximize predictive accuracy while\n",
    "automatically avoiding over-fit to the data. Support Vector machines can be defined as systems\n",
    "which use hypothesis space of a linear functions in a high dimensional feature space, trained with\n",
    "a learning algorithm from optimization theory that implements a learning bias derived from\n",
    "statistical learning theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle MNIST Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to correctly identify digits from a dataset of tens of thousands of handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split train data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, train['label'], \n",
    "                                                    test_size=.2, random_state=42)\n",
    "                                                    \n",
    "classifier = DecisionTreeClassifier(max_depth=5)\n",
    "classifier.fit(x_train,y_train)\n",
    "y_pred = classifier.predict(x_train)\n",
    "print (\"Accuracy on Training: \",sum(y_pred==y_train)/len(y_train))\n",
    "\n",
    "\n",
    "classifier1 = DecisionTreeClassifier(max_depth=9)\n",
    "classifier1.fit(X,Y)\n",
    "predictions = classifier1.predict(test)\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression - Dimensionality Reduction using PCA(Principal Component Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PrincipalComponents(n):\n",
    "    pca = PCA(n_components= n)\n",
    "    X_train1 = pca.fit_transform(X_train)\n",
    "    X_test1 = pca.transform(X_test)\n",
    "    return X_train1, X_test1\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "def LogisticRegression(X_train2, y_train2, X_test2, y_test2, penalty):\n",
    "    print(\"penalty= \", penalty)\n",
    "    regr = linear_model.LogisticRegression(solver='lbfgs',max_iter=1000, C=penalty)\n",
    "    regr.fit(X_train2, y_train2)\n",
    "    score1 = regr.score(X_train2, y_train2)\n",
    "    score2 = regr.score(X_test2, y_test2)\n",
    "    print(score1, score2)\n",
    "    Prediction = regr.predict(X_test2)\n",
    "    return score1, score2, Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine using 'rbf' kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = SVC(kernel ='rbf', C=10)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "pd.DataFrame({\"ImageId\": image_id, \"Label\": Prediction}).to_csv('datasets/mnist/svm_output.csv', \n",
    "                                                                      index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks, commonly known as Artificial Neural Networks (ANN) are quite a simulation of human brain functionality in machine learning (ML) problems. ANNs shall be noted not as a solution for all the problems that arise, but would provide better results with many other techniques altogether for various ML tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical neural networks uses the sigmoid function. Learning for an ANN is the task of adjusting weights to minimize the error. This is performed by back propagation of error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
